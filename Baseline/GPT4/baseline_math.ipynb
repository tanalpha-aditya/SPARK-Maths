{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Resource not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_gpt4.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m progress_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprogress_checkpoint.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 31\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-40\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAZURE_OPENAI_API_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mAZURE_OPENAI_ENDPOINT\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/openai/deployments/gpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_answer\u001b[39m(response):\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extracts the final answer from the response, prioritizing numbers inside brackets.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/CV/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/CV/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[1;32m    143\u001b[0m         timeout,\n\u001b[1;32m    144\u001b[0m         stream,\n\u001b[1;32m    145\u001b[0m         headers,\n\u001b[1;32m    146\u001b[0m         request_timeout,\n\u001b[1;32m    147\u001b[0m         typed_api_type,\n\u001b[1;32m    148\u001b[0m         requestor,\n\u001b[1;32m    149\u001b[0m         url,\n\u001b[1;32m    150\u001b[0m         params,\n\u001b[1;32m    151\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__prepare_create_request(\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m--> 153\u001b[0m     )\n\u001b[1;32m    155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/CV/lib/python3.9/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[1;32m    292\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    293\u001b[0m         supplied_headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    294\u001b[0m         files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m    295\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    296\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m--> 298\u001b[0m     )\n\u001b[1;32m    299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/envs/CV/lib/python3.9/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_interpret_response\u001b[39m(\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m, result: requests\u001b[38;5;241m.\u001b[39mResponse, stream: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m    699\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[0;32m--> 700\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the response(s) and a bool indicating whether it is a stream.\"\"\"\u001b[39;00m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/event-stream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m                 line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m             )\n\u001b[1;32m    706\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m         ), \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/CV/lib/python3.9/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         data \u001b[38;5;241m=\u001b[39m rbody\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 765\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(rbody)\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (JSONDecodeError, \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mAPIError(\n\u001b[1;32m    768\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from API (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrbody\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, rbody, rcode, headers\u001b[38;5;241m=\u001b[39mrheaders\n\u001b[1;32m    769\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Resource not found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from openai import AzureOpenAI\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import openai\n",
    "# from openai import OpenAI  # Correct import\n",
    "\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../../Dataset/GSM8k/modified/main_test.csv\")\n",
    "\n",
    "# OpenAI API client\n",
    "AZURE_OPENAI_ENDPOINT = \"https://wanbharsheet.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview\"\n",
    "AZURE_OPENAI_API_KEY = \"CbIITtgvIRGkbRskFMs9k9Q72tyTwTOXuOBgudIaTRbuocHVOeSQJQQJ99AKACF24PCXJ3w3AAABACOG9k6N\"\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = AZURE_OPENAI_ENDPOINT\n",
    "openai.api_key = AZURE_OPENAI_API_KEY\n",
    "openai.api_version = \"2024-02-01\"\n",
    "\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "output_file = \"output_gpt4.txt\"\n",
    "progress_file = \"progress_checkpoint.txt\"\n",
    "\n",
    "\n",
    "client = openai.ChatCompletion.create(\n",
    "    engine = \"gpt-40\",\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    base_url=f\"{AZURE_OPENAI_ENDPOINT}/openai/deployments/gpt-4o\",\n",
    ")\n",
    "\n",
    "def extract_answer(response):\n",
    "    \"\"\"Extracts the final answer from the response, prioritizing numbers inside brackets.\"\"\"\n",
    "    numbers = re.findall(r\"[\\[\\(\\{]([-+]?\\d*\\.?\\d+)[\\]\\)\\}]\", response)  # Extract numbers inside brackets\n",
    "\n",
    "    if numbers:\n",
    "        return float(numbers[-1]) if \".\" in numbers[-1] else int(numbers[-1])  # Convert to int if possible\n",
    "    return None  # If no number found\n",
    "\n",
    "def get_model_answer(question):\n",
    "    \"\"\"Generates an answer for the given question using GPT-4 with error handling.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Please reason step by step, and put your final answer inside brackets like [42] or (42).\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "    max_retries = 5\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            stream = client.chat.completions.create(\n",
    "                model=model_name, \n",
    "                messages=messages\n",
    "            )\n",
    "\n",
    "            response_text = \"\"\n",
    "            for chunk in stream:\n",
    "                if hasattr(chunk, \"choices\") and chunk.choices:\n",
    "                    delta = chunk.choices[0].delta\n",
    "                    if hasattr(delta, \"content\") and delta.content:\n",
    "                        response_text += delta.content\n",
    "            \n",
    "            return extract_answer(response_text), response_text\n",
    "        except Exception as e:\n",
    "            print(f\"API Error: {e}. Retrying {attempt+1}/{max_retries}...\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "    \n",
    "    return None, \"API Error - No response\"\n",
    "\n",
    "def get_last_completed_index():\n",
    "    \"\"\"Reads the last completed question index from the checkpoint file.\"\"\"\n",
    "    try:\n",
    "        with open(progress_file, \"r\") as f:\n",
    "            return int(f.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        return -1  # If no checkpoint file exists, start from the beginning\n",
    "\n",
    "# Resume from last checkpoint\n",
    "last_completed = get_last_completed_index()\n",
    "\n",
    "# Tracking accuracy\n",
    "correct = 0\n",
    "total = len(df)\n",
    "\n",
    "with open(output_file, \"a\") as f:\n",
    "    for index, row in tqdm(df.iterrows(), total=total, desc=\"Processing Questions\"):\n",
    "        if index <= last_completed:\n",
    "            continue  # Skip already completed questions\n",
    "\n",
    "        question = row[\"question\"]\n",
    "        true_value = row[\"value\"]\n",
    "        \n",
    "        model_answer, response_text = get_model_answer(question)\n",
    "\n",
    "        # Save progress after every question\n",
    "        f.write(f\"Question {index + 1}: {question}\\n\")\n",
    "        f.write(f\"Model Response: {response_text}\\n\")\n",
    "        f.write(f\"Extracted Answer: {model_answer}, True Answer: {true_value}\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.flush()  # Ensure data is written immediately\n",
    "\n",
    "        # Save progress checkpoint\n",
    "        with open(progress_file, \"w\") as p_file:\n",
    "            p_file.write(str(index))\n",
    "\n",
    "        # Accuracy check\n",
    "        print(model_answer, \" \", true_value)\n",
    "        if model_answer == true_value:\n",
    "            correct += 1\n",
    "\n",
    "# Final Accuracy Calculation\n",
    "accuracy = (correct / total) * 100\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Save final accuracy to file\n",
    "with open(output_file, \"a\") as f:\n",
    "    f.write(f\"\\nFinal Accuracy: {accuracy:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (0.28.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.65.2-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from openai) (4.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Downloading openai-1.65.2-py3-none-any.whl (473 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.1\n",
      "    Uninstalling openai-0.28.1:\n",
      "      Successfully uninstalled openai-0.28.1\n",
      "Successfully installed openai-1.65.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from openai==0.28) (4.67.1)\n",
      "Collecting aiohttp (from openai==0.28)\n",
      "  Downloading aiohttp-3.11.12-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->openai==0.28)\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai==0.28)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->openai==0.28)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from aiohttp->openai==0.28) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->openai==0.28)\n",
      "  Downloading frozenlist-1.5.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai==0.28)\n",
      "  Downloading multidict-6.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->openai==0.28)\n",
      "  Downloading propcache-0.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->openai==0.28)\n",
      "  Downloading yarl-1.18.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Downloading aiohttp-3.11.12-cp39-cp39-macosx_11_0_arm64.whl (456 kB)\n",
      "Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp39-cp39-macosx_11_0_arm64.whl (52 kB)\n",
      "Downloading multidict-6.1.0-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading propcache-0.3.0-cp39-cp39-macosx_11_0_arm64.whl (45 kB)\n",
      "Downloading yarl-1.18.3-cp39-cp39-macosx_11_0_arm64.whl (92 kB)\n",
      "Installing collected packages: propcache, multidict, frozenlist, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.64.0\n",
      "    Uninstalling openai-1.64.0:\n",
      "      Successfully uninstalled openai-1.64.0\n",
      "Successfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 async-timeout-5.0.1 frozenlist-1.5.0 multidict-6.1.0 openai-0.28.0 propcache-0.3.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-generativeai) (2.24.1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-generativeai) (2.162.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-generativeai) (2.10.6)\n",
      "Requirement already satisfied: tqdm in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-api-core->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.70.0-cp39-cp39-macosx_10_14_universal2.whl.metadata (3.9 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.12.14)\n",
      "Downloading google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.70.0-cp39-cp39-macosx_10_14_universal2.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: grpcio, grpcio-status, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-generativeai-0.8.4 grpcio-1.70.0 grpcio-status-1.70.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanalpha_aditya/miniconda3/envs/CV/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'google.generativeai' has no attribute 'Client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Gemini API client\u001b[39;00m\n\u001b[1;32m     13\u001b[0m GEMINI_API_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIzaSyCxoqbxiNWbs0tFn__u4FC1yddAzi7w7eI\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mgenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m(api_key\u001b[38;5;241m=\u001b[39mGEMINI_API_KEY)\n\u001b[1;32m     16\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-2.0-flash\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_gemini.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'google.generativeai' has no attribute 'Client'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import base64\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../../Dataset/GSM8k/modified/main_test.csv\")\n",
    "\n",
    "# Gemini API client\n",
    "GEMINI_API_KEY = \"AIzaSyCxoqbxiNWbs0tFn__u4FC1yddAzi7w7eI\"\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "output_file = \"output_gemini.txt\"\n",
    "progress_file = \"progress_checkpoint.txt\"\n",
    "\n",
    "def extract_answer(response):\n",
    "    \"\"\"Extracts the final answer from the response, prioritizing numbers inside brackets.\"\"\"\n",
    "    numbers = re.findall(r\"[\\[\\(\\{]([-+]?\\d*\\.?\\d+)[\\]\\)\\}]\", response)\n",
    "    \n",
    "    if numbers:\n",
    "        return float(numbers[-1]) if \".\" in numbers[-1] else int(numbers[-1])\n",
    "    return None\n",
    "\n",
    "def get_model_answer(question):\n",
    "    \"\"\"Generates an answer for the given question using Gemini with error handling.\"\"\"\n",
    "    sys_instruct = \"Please reason step by step, and put your final answer inside brackets like [42] or (42).\"\n",
    "    \n",
    "    max_retries = 5\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=model_name,\n",
    "                config={\"system_instruction\": sys_instruct},\n",
    "                contents=[question]\n",
    "            )\n",
    "            \n",
    "            response_text = response.text if hasattr(response, \"text\") else \"\"\n",
    "            return extract_answer(response_text), response_text\n",
    "        except Exception as e:\n",
    "            print(f\"API Error: {e}. Retrying {attempt+1}/{max_retries}...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    return None, \"API Error - No response\"\n",
    "\n",
    "def get_last_completed_index():\n",
    "    \"\"\"Reads the last completed question index from the checkpoint file.\"\"\"\n",
    "    try:\n",
    "        with open(progress_file, \"r\") as f:\n",
    "            return int(f.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        return -1\n",
    "\n",
    "last_completed = get_last_completed_index()\n",
    "correct = 0\n",
    "total = len(df)\n",
    "\n",
    "with open(output_file, \"a\") as f:\n",
    "    for index, row in tqdm(df.iterrows(), total=total, desc=\"Processing Questions\"):\n",
    "        if index <= last_completed:\n",
    "            continue\n",
    "        \n",
    "        question = row[\"question\"]\n",
    "        true_value = row[\"value\"]\n",
    "        \n",
    "        model_answer, response_text = get_model_answer(question)\n",
    "        \n",
    "        f.write(f\"Question {index + 1}: {question}\\n\")\n",
    "        f.write(f\"Model Response: {response_text}\\n\")\n",
    "        f.write(f\"Extracted Answer: {model_answer}, True Answer: {true_value}\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.flush()\n",
    "        \n",
    "        with open(progress_file, \"w\") as p_file:\n",
    "            p_file.write(str(index))\n",
    "        \n",
    "        print(model_answer, \" \", true_value)\n",
    "        if model_answer == true_value:\n",
    "            correct += 1\n",
    "\n",
    "accuracy = (correct / total) * 100\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "with open(output_file, \"a\") as f:\n",
    "    f.write(f\"\\nFinal Accuracy: {accuracy:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.21\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CV)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
